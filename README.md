# Mini Proyectos Laboratorio: LangChain â€” Servidor IA en Python

Este repositorio contiene una serie de **mini-proyectos progresivos** diseÃ±ados para aprender a construir sistemas de **IA aplicados a software real**, usando:

| TecnologÃ­a            | Para quÃ© se usa                                                    |
| --------------------- | ------------------------------------------------------------------ |
| **Python**            | Lenguaje principal del servidor IA                                 |
| **FastAPI**           | Crear endpoints HTTP que devuelven JSON                            |
| **LangChain**         | Orquestar modelos de lenguaje, prompts, RAG y agentes              |
| **OpenRouter**        | Acceder a modelos avanzados (Mistral, Gemini, LLaMA, Claude, etc.) |
| **Embeddings**        | Representar texto como vectores para bÃºsqueda semÃ¡ntica            |
| **ChromaDB / Qdrant** | Bases de datos vectoriales para RAG                                |

---

## ğŸ¯ Objetivo del repositorio

Aprender paso a paso a:

* Controlar y estructurar la salida de un modelo de lenguaje (sin inventos)
* Validar y tipar respuestas (`OutputParser`)
* Crear un sistema RAG (consultas basadas en documentos reales)
* Mitigar alucinaciones y justificar respuestas
* Darle **herramientas** a la IA (agentes que ejecutan funciones)
* Conectar la IA con **APIs externas** (ej: Uptask â†’ mÃ¡s adelante)

Cada mini-proyecto se construye **uno encima del anterior**, pero todos estÃ¡n organizados en carpetas independientes.

---

## ğŸ—ï¸ Estructura del repositorio

```
mini-projects-langchain/
â”‚
â”œâ”€ README.md          # Este documento
â”œâ”€ .env.example       # Variables de entorno a copiar
â”œâ”€ requirements.txt   # Dependencias compartidas
â”œâ”€ app/               # CÃ³digo comÃºn (FastAPI base + cliente LLM + utilidades)
â”‚   â”œâ”€ main.py
â”‚   â”œâ”€ routes.py
â”‚   â””â”€ services/
â”‚       â”œâ”€ llm_client.py
â”‚       â””â”€ utils.py
â”‚
â””â”€ projects/
    â”œâ”€ A1_chat_structured/
    â”œâ”€ A2_output_parser/
    â”œâ”€ A3_rag_basic/
    â”œâ”€ A3_rag_basic_v2/
    â”œâ”€ A4_rag_advanced/
    â”œâ”€ A5_tools_basic/
    â””â”€ A6_tools_external_api/
```

### Sobre el directorio `app/`

`/app` contiene **cÃ³digo base compartido** entre mini-proyectos:

* InicializaciÃ³n de **FastAPI**
* Cliente para llamar modelos en **OpenRouter**
* Helpers que se reutilizan

Cada mini-proyecto solo **extiende o monta nuevas rutas**.

---

## ğŸ§  Lista de Mini Proyectos (A1 â†’ A6)

| Mini Proyecto                        | QuÃ© aprenderÃ¡s                                    | Resultado                                   |
| ------------------------------------ | ------------------------------------------------- | ------------------------------------------- |
| **A1. Chat estructurado**            | Controlar el tono y formato                       | IA responde siguiendo un prompt fijo        |
| **A2. Output Parser**                | Validar y tipar respuestas                        | IA devuelve JSON correcto y Ãºtil            |
| **A3. RAG bÃ¡sico**                   | Cargar & dividir documentos, embeddings, bÃºsqueda | IA usa conocimiento real sin inventar       |
| **A3. RAG bÃ¡sico V2**                | Cargar & dividir documentos, embeddings, bÃºsqueda | IA usa conocimiento real sin inventar       |
| **A4. RAG avanzado**                 | Anti-alucinaciones (score, top-k, evidencia)      | IA justifica sus respuestas                 |
| **A5. Tools / Agentes**              | Dar habilidades a la IA                           | IA puede ejecutar funciones automÃ¡ticamente |
| **A6. API externa como herramienta** | IntegraciÃ³n IA â†” servicios externos               | IA consulta datos reales desde web/API      |

Cada carpeta contiene:

```
- README.md (explicaciÃ³n detallada)
- CÃ³digo paso a paso
- Ejercicios
- Pruebas con cURL / Thunder Client
```

---

## âš™ï¸ InstalaciÃ³n del entorno

### 1) Crear entorno virtual

```bash
python -m venv .venv
source .venv/bin/activate      # mac / linux
.venv\Scripts\activate         # windows
```

### 2) Instalar dependencias

```bash
pip install --upgrade pip # opcional
pip install -r requirements.txt
```

### 3) Configurar `.env`

Crea tu archivo desde la plantilla:

```bash
cp .env.example .env
```

Edita OPENROUTER_API_KEY:

Puedes editar tambiÃ©n DEFAULT_MODEL si deseas usar otro modelo de OpenRouter.

```
OPENROUTER_API_KEY=API_KEY_HERE
OPENROUTER_BASE_URL=https://openrouter.ai/api/v1
DEFAULT_MODEL=meta-llama/llama-3.3-8b-instruct:free
```

> La API key se obtiene en: [https://openrouter.ai/keys](https://openrouter.ai/keys)

---

## â–¶ï¸ Ejecutar el servidor desde entorno virtual

```bash
uvicorn app.main:app --reload --port 8000
```

Probamos:

```
GET http://localhost:8000/health
GET http://localhost:8000/test-llm
```

---


Â¡Perfecto! AquÃ­ tienes un **apartado completo y muy claro**, detallando **pyenv, configuraciÃ³n de shell, entorno virtual, pip y dependencias sin cachÃ©**, listo para incluir en tu README para este equipo macOS Intel:

---

## âš ï¸ Consideraciones para macOS Intel (Python 3.11)

En este equipo especÃ­fico con macOS 14 Intel, se requieren algunos pasos adicionales para evitar conflictos de dependencias:

---

### 1ï¸âƒ£ Instalar pyenv y configurar Python 3.11

1. Instalamos `pyenv`:

```bash
brew install pyenv
```

2. Instalamos Python 3.11 y lo configuramos como **versiÃ³n global** del equipo:

```bash
pyenv install 3.11.8
pyenv global 3.11.8
```

3. Verificamos que se use la versiÃ³n correcta:

```bash
python3 -V       # Debe mostrar Python 3.11.8
which python3    # Debe apuntar a ~/.pyenv/versions/3.11.8/bin/python3
```

---

### 2ï¸âƒ£ Configurar el shell (`zsh`) para pyenv

Para que pyenv funcione correctamente en todas las sesiones, aÃ±adimos estas lÃ­neas a **`~/.zshrc`** o **`~/.zprofile`**:

```bash
export PYENV_ROOT="$HOME/.pyenv"
export PATH="$PYENV_ROOT/bin:$PATH"
eval "$(pyenv init - zsh)"
```

Luego recargamos la configuraciÃ³n:

```bash
source ~/.zshrc
```

> Esto asegura que `python3` y `pip` apunten a la versiÃ³n de pyenv, no al Python del sistema.

---

### 3ï¸âƒ£ Crear y activar entorno virtual

1. Creamos un entorno virtual dentro del proyecto:

```bash
python -m venv .venv
```

2. Activamos el entorno:

```bash
source .venv/bin/activate   # macOS / Linux
```

3. Verificamos que `python` y `pip` apunten al entorno virtual:

```bash
which python   # Debe apuntar a .venv/bin/python
which pip      # Debe apuntar a .venv/bin/pip
python -V      # Debe mostrar Python 3.11.8
```

---

### 4ï¸âƒ£ Instalar pip para la versiÃ³n de pyenv

Si el entorno no tiene pip:

```bash
python -m ensurepip
python -m pip install --upgrade pip
```

> Ahora pip estÃ¡ correctamente asociado a Python 3.11 del entorno virtual.

---

### 5ï¸âƒ£ Forzar NumPy < 2

Para compatibilidad con paquetes compilados (PyTorch, sentence-transformers):

```bash
pip uninstall numpy -y
pip install "numpy<2"
```

---

### 6ï¸âƒ£ Instalar dependencias sin usar cachÃ©

```bash
pip install --no-cache-dir -r requirements.txt
```

> Esto evita que se instalen versiones antiguas o incompatibles de los paquetes.

---

### 7ï¸âƒ£ Verificar instalaciÃ³n

```bash
python -c "import numpy; print(numpy.__version__)"
python -c "import torch; print(torch.__version__)"
python -c "from sentence_transformers import SentenceTransformer; print('ST OK')"
```

Todo debe funcionar sin errores.

---

### 8ï¸âƒ£ Arrancar el servidor

Con el entorno activado:

```bash
uvicorn app.main:app --reload --port 8000
```

> Ahora el servidor funciona correctamente, sin errores de NumPy o PyTorch en este equipo.

---

Si quieres, puedo hacer una **versiÃ³n resumida â€œnota rÃ¡pida del equipoâ€**, de unas 10-12 lÃ­neas, perfecta para poner **al final del README** y que quede claro para cualquier persona que use este Mac Intel.

Â¿Quieres que haga eso?

